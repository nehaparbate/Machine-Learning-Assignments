{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees Implementation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, impurity='gini', max_depth=10, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.impurity = impurity\n",
    "        self.max_depth= max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        \n",
    "        criterion_funcs = {'gini': self.calculate_gini_impurity, \n",
    "                           'entropy': self.calculate_entropy,\n",
    "                           'misclassification_rate': self.calculate_misclassification_rate}\n",
    "        self.homogeneity_measure = criterion_funcs.get(impurity, self.calculate_gini_impurity)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        self.tree = self.split(X, y, 0)   \n",
    "        \n",
    "    def calculate_gini_impurity(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        proportions = counts / len(y)\n",
    "        return 1 - np.sum(proportions**2)\n",
    "    \n",
    "    def calculate_entropy(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        proportions = counts / len(y)\n",
    "        return -np.sum(proportions * np.log2(proportions))\n",
    "    \n",
    "    def calculate_misclassification_rate(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        proportions = counts / len(y)\n",
    "        return 1 - np.max(proportions)\n",
    "    \n",
    "    def split(self, X, y, d):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        if n_samples < self.min_samples_split or d> self.max_depth:\n",
    "            return {'leaf_value': np.round(np.mean(y))}\n",
    "        \n",
    "        b_feature, b_threshold, b_impurity = None, None, np.inf\n",
    "        b_l_X, b_l_y, b_r_X, b_r_y = None, None, None, None\n",
    "        \n",
    "        for selected_feat in range(n_features):\n",
    "            ths = np.unique(X[:, selected_feat])\n",
    "            for t in ths:\n",
    "                r_partition_ind = X[:, selected_feat] > t\n",
    "                l_partition_ind = X[:, selected_feat] <= t\n",
    "\n",
    "                if  len(y[r_partition_ind]) > 0 and len(y[l_partition_ind]) > 0:\n",
    "                    l_y, r_y = y[l_partition_ind], y[r_partition_ind]\n",
    "                    n_left, n_right = len(l_y), len(r_y)\n",
    "                    total_samples = n_left + n_right\n",
    "                    impurity = (n_left / total_samples) * self.homogeneity_measure(l_y) \\\n",
    "         + (n_right / total_samples) * self.homogeneity_measure(r_y)\n",
    "\n",
    "                    if impurity < b_impurity:\n",
    "                        b_feature, b_threshold, b_impurity = selected_feat, t, impurity\n",
    "                        b_l_X, b_l_y = X[l_partition_ind], y[l_partition_ind]\n",
    "                        b_r_X, b_r_y = X[r_partition_ind], y[r_partition_ind]\n",
    "\n",
    "        if b_feature is not None:\n",
    "            node = {}\n",
    "            node['feature'] = b_feature\n",
    "            node['threshold'] = b_threshold\n",
    "            node['left'] = self.split(b_l_X, b_l_y, d+ 1)\n",
    "            node['right'] = self.split(b_r_X, b_r_y, d+ 1)\n",
    "            return node\n",
    "\n",
    "        return {'leaf_value': np.round(np.mean(y))}\n",
    "        \n",
    "    def predict_sample(self, x, node):\n",
    "        while 'leaf_value' not in node:\n",
    "            if x[node['feature']] <= node['threshold']:\n",
    "                node = node['left']\n",
    "            else:\n",
    "                node = node['right']\n",
    "        return node['leaf_value']\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        X.reset_index(drop=True, inplace=True)\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            y_pred[i] = self.predict_sample(X.loc[i], self.tree)  \n",
    "        return y_pred\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing for Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports needed for the script\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from IPython.display import Image as PImage\n",
    "from subprocess import check_call\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Loading the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Store our test passenger IDs for easy access\n",
    "PassengerId = test['PassengerId']\n",
    "\n",
    "# Showing overview of the train dataset\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train = train.copy() \n",
    "\n",
    "full_data = [train, test]\n",
    "\n",
    "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "# Create new feature IsAlone from FamilySize\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "# Remove all NULLS in the Embarked column\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "# Remove all NULLS in the Fare column\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "\n",
    "# Remove all NULLS in the Age column\n",
    "for dataset in full_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    # Next line has been improved to avoid warning\n",
    "    dataset.loc[np.isnan(dataset['Age']), 'Age'] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Master\": 2, \"Mrs\": 3, \"Miss\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp','Sex']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "\n",
    "test  = test.drop(drop_elements, axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1 : Testing the Descision Tree Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = train['Survived']\n",
    "X = train.drop('Survived', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "decision_tree = DecisionTree(max_depth=5)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Acc_for_DT = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Decision Tree: 79.33%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Decision Tree: {:.2f}%\".format(Acc_for_DT * 100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class RandomForest:\n",
    "    def __init__(self, classifier, num_trees, min_features):\n",
    "        self.classifier = classifier\n",
    "        self.num_trees = num_trees\n",
    "        self.min_features = min_features\n",
    "        self.trees = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = X.values  \n",
    "        y = y.values\n",
    "        \n",
    "        for i in range(self.num_trees):\n",
    "            # select random number of samples \n",
    "\n",
    "            sample_count = np.random.randint(1, X.shape[0]+1)\n",
    "            sample_ids = np.random.choice(X.shape[0], sample_count, replace=True)\n",
    "            X_b = X[sample_ids]\n",
    "            y_b = y[sample_ids]\n",
    "            \n",
    "            # select a random subset of features\n",
    "            feat_count = np.random.randint(self.min_features, X.shape[1]+1)\n",
    "            f_ids = np.random.choice(X.shape[1], feat_count, replace=False)\n",
    "            X_b = X_b[:, f_ids]\n",
    "            \n",
    "            tree = self.classifier(max_depth=7, \n",
    "                                    min_samples_split=4, min_samples_leaf=2)\n",
    "            tree.fit(X_b, y_b)\n",
    "            \n",
    "            self.trees.append((tree, f_ids))\n",
    "            \n",
    "    def predict(self, X):\n",
    "        X = X.values  \n",
    "        \n",
    "        pred_arr = []\n",
    "        for tree, f_ids in self.trees:\n",
    "            sub_X = X[:, f_ids]\n",
    "            pred_arr.append(tree.predict(sub_X))\n",
    "        \n",
    "        pred_arr = np.array(pred_arr).astype(int)\n",
    "        return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=pred_arr)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest: 81.56%\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForest(classifier=DecisionTree, num_trees=50, min_features=4)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "Acc_for_RF = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy for Random Forest: {:.2f}%\".format(Acc_for_RF * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self, weak_learner, num_learners, learning_rate):\n",
    "        self.weak_learner = weak_learner\n",
    "        self.num_learners = num_learners\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        sample_count = X.shape[0]\n",
    "        wts = np.ones(sample_count) / sample_count\n",
    "        \n",
    "        self.m_arr = []\n",
    "        self.al_arr = []\n",
    "        \n",
    "        for _ in range(self.num_learners):\n",
    "            ml = self.weak_learner()\n",
    "            ml.fit(X, y)\n",
    "            y_pred = ml.predict(X)\n",
    "            error = np.mean(np.abs(y_pred - y) / 2 * wts) / np.mean(wts)\n",
    "            if error > 0.5:\n",
    "                break\n",
    "            alpha = self.learning_rate * np.log((1 - error) / error)\n",
    "            self.m_arr.append(ml)\n",
    "            self.al_arr.append(alpha)\n",
    "            \n",
    "            wts *= np.exp(-alpha * y * y_pred)\n",
    "            wts /= np.sum(wts)\n",
    "\n",
    "            \n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        y_pred = np.zeros(n_samples)\n",
    "        \n",
    "        for i in range(len(self.m_arr)):\n",
    "            ml = self.m_arr[i]\n",
    "            al = self.al_arr[i]\n",
    "            y_pred += al * ml.predict(X)\n",
    "        \n",
    "        return np.sign(y_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Ada Boost: 80.45%\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoost(weak_learner=DecisionTree, num_learners=100, learning_rate=0.1)\n",
    "\n",
    "\n",
    "ab.fit(X_train, y_train)\n",
    "y_pred_ab = ab.predict(X_test)\n",
    "\n",
    "Acc_for_AdB = accuracy_score(y_test, y_pred_ab)\n",
    "print(\"Accuracy for Ada Boost: {:.2f}%\".format(Acc_for_AdB * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the Accuracy for 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Decision Tree: 79.33%\n",
      "Accuracy for Random Forest: 81.56%\n",
      "Accuracy for Ada Boost: 80.45%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Decision Tree: {:.2f}%\".format(Acc_for_DT * 100))\n",
    "print(\"Accuracy for Random Forest: {:.2f}%\".format(Acc_for_RF * 100))\n",
    "print(\"Accuracy for Ada Boost: {:.2f}%\".format(Acc_for_AdB * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
